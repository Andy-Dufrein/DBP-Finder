{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload mode to automatically reload all modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import ankh\n",
    "import clearml\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from clearml import Logger, Task\n",
    "from data_prepare import get_embed_clustered_df, make_folds\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_utils import (CustomBatchSampler, SequenceDataset,\n",
    "                         custom_collate_fn, train_fn, validate_fn, load_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частота классов по батчам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_embed_clustered_df(\n",
    "    embedding_path=\"../data/embeddings/ankh_embeddings/train_p2_2d.h5\",\n",
    "    csv_path=\"../data/splits/train_p2.csv\",\n",
    ")\n",
    "train_folds, valid_folds = make_folds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceDataset(df)\n",
    "sampler = CustomBatchSampler(dataset, batch_size=64)\n",
    "dataloader = DataLoader(\n",
    "        dataset,\n",
    "        num_workers=1,\n",
    "        batch_sampler=sampler,\n",
    "        collate_fn=custom_collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69872"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ratio = {}\n",
    "for i, (_, y) in enumerate(dataloader):\n",
    "    zero_freq = torch.sum(y == 0).item()\n",
    "    ones_freq = torch.sum(y == 1).item()\n",
    "\n",
    "    freq_ratio[i] = zero_freq / ones_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_values = list(freq_ratio.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0317460317460319"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ratio_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, (_, y) in enumerate(dataloader):\n",
    "    count += len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091.75"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models()\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13013775, 13013775)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = load_embeddings_to_df(\"../data/embeddings/ankh_embeddings/not_annotated_seqs_v1_2d.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inderence_dataset = InferenceDataset(embed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataloader = DataLoader(\n",
    "        inderence_dataset,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "        batch_size=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_, x = next(iter(inference_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for id_, x in inference_dataloader:\n",
    "        x = x.to(DEVICE)\n",
    "        ens_logits = []\n",
    "\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            model = model.to(DEVICE)\n",
    "            output = model(x)\n",
    "\n",
    "            logits = output.logits\n",
    "            ens_logits.append(logits)\n",
    "\n",
    "        ens_logits = torch.stack(ens_logits, dim=0)\n",
    "        ens_logits = torch.mean(ens_logits, dim=0)\n",
    "        prob_score = torch.sigmoid(ens_logits)\n",
    "\n",
    "        identifiers.extend(id_)\n",
    "        scores.append(prob_score.cpu().numpy().item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание на неанноитрованных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv(\"../data/not_annotated/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = predictions_df.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/not_annotated/not_annotated_seqs_with_org.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arabidopsis thaliana', 'Bacillus subtilis (strain 168)',\n",
       "       'Saccharomyces cerevisiae (strain ATCC 204508 / S288c)',\n",
       "       'Escherichia coli (strain K12)', 'Homo sapiens',\n",
       "       'Organism name not found', 'Komagataella pastoris'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Organism\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictions_df.merge(df, on=\"identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"Organism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = {}\n",
    "for name, sub_df in grouped:\n",
    "    for threshold in thresholds:\n",
    "        count = len(sub_df[sub_df[\"score\"] > threshold])\n",
    "        group_name = name + \"_\" + str(threshold)\n",
    "        stats[group_name] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
